{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from collections import Counter\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/roesman_raja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/roesman_raja/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/roesman_raja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/roesman_raja/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: make me the slangremover function for english language with working slang_dict from github\n",
    "\n",
    "slang_dict = {\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"lmfao\": \"laughing my f***ing ass off\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"diy\": \"do it yourself\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"nvm\": \"nevermind\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"nvm\": \"nevermind\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ttyl\": \"talk to you later\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "\n",
    "    text = text.replace('\\n', ' ') # replace new line into space\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    text = text.strip(' ') # remove characters space from both left and right text\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\") \n",
    "\n",
    "def tokenizingText(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]  \n",
    "    return tokens\n",
    "\n",
    "def deSlangText(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.lower() in slang_dict:\n",
    "            new_text.append(slang_dict[word.lower()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def filteringText(text):  # Remove stopwords in a text\n",
    "    listStopwords = set(stopwords.words('english'))\n",
    "    filtered = [w for w in text if not w.lower() in listStopwords]\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    "\n",
    "# Lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_words\n",
    "\n",
    "def stemmingText(text):  # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "    stemmer = PorterStemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def toSentence(list_words): # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = tokenizingText(example_sent)\n",
    "# converts the words in word_tokens to lower case and then checks whether \n",
    "#they are present in stop_words or not\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "#with no lower case conversion\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "\tif w not in stop_words:\n",
    "\t\tfiltered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad . bad .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if that summary isn't enough for you , how abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>still haven't got the point ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>of any horror filmmaker in the world , kiyoshi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>i rate this metaphysical look at isolation a 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentiment\n",
       "0                                            bad . bad .          0\n",
       "1                                                  bad .          0\n",
       "2      that one word seems to pretty much sums up bey...          0\n",
       "3      if that summary isn't enough for you , how abo...          0\n",
       "4                          still haven't got the point ?          0\n",
       "...                                                  ...        ...\n",
       "64715  people are shot with guns but there is little ...          1\n",
       "64716  seeing black silhouettes on computer screens i...          1\n",
       "64717  kurosawa is not going for and easy visual shoc...          1\n",
       "64718  of any horror filmmaker in the world , kiyoshi...          1\n",
       "64719  i rate this metaphysical look at isolation a 7...          1\n",
       "\n",
       "[64720 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('output_sentences.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['sentence'].astype(str).apply(cleaningText)\n",
    "df['casefolding'] = df['text_clean'].apply(casefoldingText)\n",
    "df['text_deslanged'] = df['casefolding'].apply(deSlangText)\n",
    "df['text_preprocessed'] = df['text_deslanged'].apply(tokenizingText)\n",
    "df['text_filtered'] = df['text_preprocessed'].apply(filteringText)\n",
    "df['text_stemmed'] = df['text_filtered'].apply(lemmatize_text)\n",
    "df['text_classifier'] = df['text_filtered'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>casefolding</th>\n",
       "      <th>text_deslanged</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>text_filtered</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad . bad .</td>\n",
       "      <td>0</td>\n",
       "      <td>bad  bad</td>\n",
       "      <td>bad  bad</td>\n",
       "      <td>bad bad</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>[bad, bad, bad, bad]</td>\n",
       "      <td>[bad, bad, bad, bad]</td>\n",
       "      <td>bad bad bad bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad .</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>[bad]</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>bad bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>0</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>[that, one, word, seems, to, pretty, much, sum...</td>\n",
       "      <td>[one, word, seems, pretty, much, sums, beyond,...</td>\n",
       "      <td>[one, word, seems, pretty, much, sum, beyond, ...</td>\n",
       "      <td>one word seems pretty much sums beyond valley ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if that summary isn't enough for you , how abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>if that summary isnt enough for you  how about...</td>\n",
       "      <td>if that summary isnt enough for you  how about...</td>\n",
       "      <td>if that summary isnt enough for you how about ...</td>\n",
       "      <td>[if, that, summary, is, nt, enough, for, you, ...</td>\n",
       "      <td>[summary, nt, enough, ta, ta, ta, summary, nt,...</td>\n",
       "      <td>[summary, nt, enough, ta, ta, ta, summary, nt,...</td>\n",
       "      <td>summary nt enough ta ta ta summary nt enough t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>still haven't got the point ?</td>\n",
       "      <td>0</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>[still, have, nt, got, the, point]</td>\n",
       "      <td>[still, nt, got, point, still, nt, got, point]</td>\n",
       "      <td>[still, nt, got, point, still, nt, got, point]</td>\n",
       "      <td>still nt got point still nt got point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>1</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>[people, are, shot, with, guns, but, there, is...</td>\n",
       "      <td>[people, shot, guns, little, blood, evidence, ...</td>\n",
       "      <td>[people, shot, gun, little, blood, evidence, p...</td>\n",
       "      <td>people shot guns little blood evidence people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>1</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>[seeing, black, silhouettes, on, computer, scr...</td>\n",
       "      <td>[seeing, black, silhouettes, computer, screens...</td>\n",
       "      <td>[seeing, black, silhouette, computer, screen, ...</td>\n",
       "      <td>seeing black silhouettes computer screens imme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>[kurosawa, is, not, going, for, and, easy, vis...</td>\n",
       "      <td>[kurosawa, going, easy, visual, shock, deeper,...</td>\n",
       "      <td>[kurosawa, going, easy, visual, shock, deeper,...</td>\n",
       "      <td>kurosawa going easy visual shock deeper metaph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>of any horror filmmaker in the world , kiyoshi...</td>\n",
       "      <td>1</td>\n",
       "      <td>of any horror filmmaker in the world  kiyoshi ...</td>\n",
       "      <td>of any horror filmmaker in the world  kiyoshi ...</td>\n",
       "      <td>of any horror filmmaker in the world kiyoshi k...</td>\n",
       "      <td>[of, any, horror, filmmaker, in, the, world, k...</td>\n",
       "      <td>[horror, filmmaker, world, kiyoshi, kurosawa, ...</td>\n",
       "      <td>[horror, filmmaker, world, kiyoshi, kurosawa, ...</td>\n",
       "      <td>horror filmmaker world kiyoshi kurosawa one wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>i rate this metaphysical look at isolation a 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>i rate this metaphysical look at isolation a  ...</td>\n",
       "      <td>i rate this metaphysical look at isolation a  ...</td>\n",
       "      <td>i rate this metaphysical look at isolation a o...</td>\n",
       "      <td>[i, rate, this, metaphysical, look, at, isolat...</td>\n",
       "      <td>[rate, metaphysical, look, isolation, scale, s...</td>\n",
       "      <td>[rate, metaphysical, look, isolation, scale, s...</td>\n",
       "      <td>rate metaphysical look isolation scale scale r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentiment  \\\n",
       "0                                            bad . bad .          0   \n",
       "1                                                  bad .          0   \n",
       "2      that one word seems to pretty much sums up bey...          0   \n",
       "3      if that summary isn't enough for you , how abo...          0   \n",
       "4                          still haven't got the point ?          0   \n",
       "...                                                  ...        ...   \n",
       "64715  people are shot with guns but there is little ...          1   \n",
       "64716  seeing black silhouettes on computer screens i...          1   \n",
       "64717  kurosawa is not going for and easy visual shoc...          1   \n",
       "64718  of any horror filmmaker in the world , kiyoshi...          1   \n",
       "64719  i rate this metaphysical look at isolation a 7...          1   \n",
       "\n",
       "                                              text_clean  \\\n",
       "0                                               bad  bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you  how about...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world  kiyoshi ...   \n",
       "64719  i rate this metaphysical look at isolation a  ...   \n",
       "\n",
       "                                             casefolding  \\\n",
       "0                                               bad  bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you  how about...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world  kiyoshi ...   \n",
       "64719  i rate this metaphysical look at isolation a  ...   \n",
       "\n",
       "                                          text_deslanged  \\\n",
       "0                                                bad bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you how about ...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world kiyoshi k...   \n",
       "64719  i rate this metaphysical look at isolation a o...   \n",
       "\n",
       "                                       text_preprocessed  \\\n",
       "0                                             [bad, bad]   \n",
       "1                                                  [bad]   \n",
       "2      [that, one, word, seems, to, pretty, much, sum...   \n",
       "3      [if, that, summary, is, nt, enough, for, you, ...   \n",
       "4                     [still, have, nt, got, the, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, are, shot, with, guns, but, there, is...   \n",
       "64716  [seeing, black, silhouettes, on, computer, scr...   \n",
       "64717  [kurosawa, is, not, going, for, and, easy, vis...   \n",
       "64718  [of, any, horror, filmmaker, in, the, world, k...   \n",
       "64719  [i, rate, this, metaphysical, look, at, isolat...   \n",
       "\n",
       "                                           text_filtered  \\\n",
       "0                                   [bad, bad, bad, bad]   \n",
       "1                                             [bad, bad]   \n",
       "2      [one, word, seems, pretty, much, sums, beyond,...   \n",
       "3      [summary, nt, enough, ta, ta, ta, summary, nt,...   \n",
       "4         [still, nt, got, point, still, nt, got, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, shot, guns, little, blood, evidence, ...   \n",
       "64716  [seeing, black, silhouettes, computer, screens...   \n",
       "64717  [kurosawa, going, easy, visual, shock, deeper,...   \n",
       "64718  [horror, filmmaker, world, kiyoshi, kurosawa, ...   \n",
       "64719  [rate, metaphysical, look, isolation, scale, s...   \n",
       "\n",
       "                                            text_stemmed  \\\n",
       "0                                   [bad, bad, bad, bad]   \n",
       "1                                             [bad, bad]   \n",
       "2      [one, word, seems, pretty, much, sum, beyond, ...   \n",
       "3      [summary, nt, enough, ta, ta, ta, summary, nt,...   \n",
       "4         [still, nt, got, point, still, nt, got, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, shot, gun, little, blood, evidence, p...   \n",
       "64716  [seeing, black, silhouette, computer, screen, ...   \n",
       "64717  [kurosawa, going, easy, visual, shock, deeper,...   \n",
       "64718  [horror, filmmaker, world, kiyoshi, kurosawa, ...   \n",
       "64719  [rate, metaphysical, look, isolation, scale, s...   \n",
       "\n",
       "                                         text_classifier  \n",
       "0                                        bad bad bad bad  \n",
       "1                                                bad bad  \n",
       "2      one word seems pretty much sums beyond valley ...  \n",
       "3      summary nt enough ta ta ta summary nt enough t...  \n",
       "4                  still nt got point still nt got point  \n",
       "...                                                  ...  \n",
       "64715  people shot guns little blood evidence people ...  \n",
       "64716  seeing black silhouettes computer screens imme...  \n",
       "64717  kurosawa going easy visual shock deeper metaph...  \n",
       "64718  horror filmmaker world kiyoshi kurosawa one wa...  \n",
       "64719  rate metaphysical look isolation scale scale r...  \n",
       "\n",
       "[64720 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_ngram_vectorizer = TfidfVectorizer()\n",
    "X = df['text_classifier'].values\n",
    "y = df['sentiment'].values\n",
    "\n",
    "X_bi = tf_idf_ngram_vectorizer.fit_transform(X)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_bi, y, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can experiment with different kernels (e.g., 'rbf', 'poly')\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.6784243  0.6791967  0.65825393 0.67937162 0.67911409 0.67164563\n",
      " 0.68658254 0.67808396 0.68503734 0.68297708]\n",
      "Mean cross-validation score: 0.6778687195207502\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(svm_model, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6812036464771323\n",
      "Confusion Matrix:\n",
      " [[8521 4151]\n",
      " [4102 9114]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67     12672\n",
      "           1       0.69      0.69      0.69     13216\n",
      "\n",
      "    accuracy                           0.68     25888\n",
      "   macro avg       0.68      0.68      0.68     25888\n",
      "weighted avg       0.68      0.68      0.68     25888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to dense and then to PyTorch tensors\n",
    "X_bi_dense = X_bi.toarray()\n",
    "X_tensor = torch.tensor(X_bi_dense, dtype=torch.float32).to(device)  # Move to GPU\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor.cpu(), y_tensor.cpu(), test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and test sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # 1 layer\n",
    "        c0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)  # 1 layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Loss: 0.6321\n",
      "Epoch [2/5], Average Loss: 0.4535\n",
      "Epoch [3/5], Average Loss: 0.3506\n",
      "Epoch [4/5], Average Loss: 0.2909\n",
      "Epoch [5/5], Average Loss: 0.2499\n",
      "Training Losses per Epoch: [0.6321140209080949, 0.45353933119351625, 0.3505608503518034, 0.29092366034794087, 0.24985271856139676]\n"
     ]
    }
   ],
   "source": [
    "# Define input dimensions and create model\n",
    "input_dim = X_bi_dense.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim).to(device)  # Move model to GPU\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0  # To calculate average loss per epoch\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move batch to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch.unsqueeze(1))  # Add sequence dimension\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Optionally, print final training losses\n",
    "print(\"Training Losses per Epoch:\", train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6706\n",
      "Precision: 0.6819\n",
      "Recall: 0.6650\n",
      "F1 Score: 0.6733\n",
      "Confusion Matrix:\n",
      "[[8572 4100]\n",
      " [4428 8788]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move to GPU\n",
    "            outputs = model(X_batch.unsqueeze(1))  # Add sequence dimension\n",
    "            preds = (outputs.squeeze() > 0.5).float()  # Convert probabilities to binary class labels\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())  # Move predictions to CPU and convert to numpy\n",
    "            all_labels.extend(y_batch.cpu().numpy())  # Move labels to CPU and convert to numpy\n",
    "\n",
    "    # Convert lists to numpy arrays for metric calculations\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "\n",
    "# Call the evaluation function\n",
    "evaluate_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love this product! It's amazing and works perfectly.\n",
      "Sentiment: [{'label': 'HAPPY', 'score': 0.9787024259567261}]\n",
      "\n",
      "Text: This is the worst experience I've ever had.\n",
      "Sentiment: [{'label': 'SAD', 'score': 0.9854721426963806}]\n",
      "\n",
      "Text: It's okay, nothing special but not bad either.\n",
      "Sentiment: [{'label': 'SAD', 'score': 0.8439469933509827}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a function for sentiment analysis\n",
    "def analyze_sentiment(text):\n",
    "    result = pipe(text)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "texts = [\n",
    "    \"I love this product! It's amazing and works perfectly.\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"It's okay, nothing special but not bad either.\",\n",
    "]\n",
    "\n",
    "# Analyze sentiment for each text\n",
    "for text in texts:\n",
    "    sentiment = analyze_sentiment(text)\n",
    "    print(f\"Text: {text}\\nSentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        # Resetting indices to avoid KeyErrors\n",
    "        self.texts = texts.reset_index(drop=True).tolist()\n",
    "        self.labels = labels.reset_index(drop=True).tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data: replace with your actual data\n",
    "texts = df['text_classifier']\n",
    "labels = df['sentiment']\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\")\n",
    "\n",
    "# Create DataLoader\n",
    "max_len = 128\n",
    "train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_len)\n",
    "test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 1618/1618 [06:38<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Average Loss: 0.6717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1618/1618 [06:39<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4, Average Loss: 0.5929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1618/1618 [06:39<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4, Average Loss: 0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1618/1618 [06:39<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4, Average Loss: 0.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * 4  # Number of epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6428\n"
     ]
    }
   ],
   "source": [
    "# Optionally evaluate the model\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluate_model(model, test_loader, device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
