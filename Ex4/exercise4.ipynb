{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: make me the slangremover function for english language with working slang_dict from github\n",
    "\n",
    "slang_dict = {\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"lmfao\": \"laughing my f***ing ass off\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"diy\": \"do it yourself\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"nvm\": \"nevermind\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"nvm\": \"nevermind\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ttyl\": \"talk to you later\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "\n",
    "    text = text.replace('\\n', ' ') # replace new line into space\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    text = text.strip(' ') # remove characters space from both left and right text\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\") \n",
    "\n",
    "def tokenizingText(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]  \n",
    "    return tokens\n",
    "\n",
    "def deSlangText(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.lower() in slang_dict:\n",
    "            new_text.append(slang_dict[word.lower()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def filteringText(text):  # Remove stopwords in a text\n",
    "    listStopwords = set(stopwords.words('english'))\n",
    "    filtered = [w for w in text if not w.lower() in listStopwords]\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    "\n",
    "# Lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_words\n",
    "\n",
    "def stemmingText(text):  # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "    stemmer = PorterStemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def toSentence(list_words): # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = tokenizingText(example_sent)\n",
    "# converts the words in word_tokens to lower case and then checks whether \n",
    "#they are present in stop_words or not\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "#with no lower case conversion\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "\tif w not in stop_words:\n",
    "\t\tfiltered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad . bad .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if that summary isn't enough for you , how abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>still haven't got the point ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>of any horror filmmaker in the world , kiyoshi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>i rate this metaphysical look at isolation a 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentiment\n",
       "0                                            bad . bad .          0\n",
       "1                                                  bad .          0\n",
       "2      that one word seems to pretty much sums up bey...          0\n",
       "3      if that summary isn't enough for you , how abo...          0\n",
       "4                          still haven't got the point ?          0\n",
       "...                                                  ...        ...\n",
       "64715  people are shot with guns but there is little ...          1\n",
       "64716  seeing black silhouettes on computer screens i...          1\n",
       "64717  kurosawa is not going for and easy visual shoc...          1\n",
       "64718  of any horror filmmaker in the world , kiyoshi...          1\n",
       "64719  i rate this metaphysical look at isolation a 7...          1\n",
       "\n",
       "[64720 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('output_sentences.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['sentence'].astype(str).apply(cleaningText)\n",
    "df['casefolding'] = df['text_clean'].apply(casefoldingText)\n",
    "df['text_deslanged'] = df['casefolding'].apply(deSlangText)\n",
    "df['text_preprocessed'] = df['text_deslanged'].apply(tokenizingText)\n",
    "df['text_filtered'] = df['text_preprocessed'].apply(filteringText)\n",
    "df['text_stemmed'] = df['text_filtered'].apply(lemmatize_text)\n",
    "df['text_classifier'] = df['text_filtered'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>casefolding</th>\n",
       "      <th>text_deslanged</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>text_filtered</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad . bad .</td>\n",
       "      <td>0</td>\n",
       "      <td>bad  bad</td>\n",
       "      <td>bad  bad</td>\n",
       "      <td>bad bad</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>[bad, bad, bad, bad]</td>\n",
       "      <td>[bad, bad, bad, bad]</td>\n",
       "      <td>bad bad bad bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad .</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>[bad]</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>bad bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>0</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>[that, one, word, seems, to, pretty, much, sum...</td>\n",
       "      <td>[one, word, seems, pretty, much, sums, beyond,...</td>\n",
       "      <td>[one, word, seems, pretty, much, sum, beyond, ...</td>\n",
       "      <td>one word seems pretty much sums beyond valley ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if that summary isn't enough for you , how abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>if that summary isnt enough for you  how about...</td>\n",
       "      <td>if that summary isnt enough for you  how about...</td>\n",
       "      <td>if that summary isnt enough for you how about ...</td>\n",
       "      <td>[if, that, summary, is, nt, enough, for, you, ...</td>\n",
       "      <td>[summary, nt, enough, ta, ta, ta, summary, nt,...</td>\n",
       "      <td>[summary, nt, enough, ta, ta, ta, summary, nt,...</td>\n",
       "      <td>summary nt enough ta ta ta summary nt enough t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>still haven't got the point ?</td>\n",
       "      <td>0</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>[still, have, nt, got, the, point]</td>\n",
       "      <td>[still, nt, got, point, still, nt, got, point]</td>\n",
       "      <td>[still, nt, got, point, still, nt, got, point]</td>\n",
       "      <td>still nt got point still nt got point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>1</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>[people, are, shot, with, guns, but, there, is...</td>\n",
       "      <td>[people, shot, guns, little, blood, evidence, ...</td>\n",
       "      <td>[people, shot, gun, little, blood, evidence, p...</td>\n",
       "      <td>people shot guns little blood evidence people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>1</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>[seeing, black, silhouettes, on, computer, scr...</td>\n",
       "      <td>[seeing, black, silhouettes, computer, screens...</td>\n",
       "      <td>[seeing, black, silhouette, computer, screen, ...</td>\n",
       "      <td>seeing black silhouettes computer screens imme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>[kurosawa, is, not, going, for, and, easy, vis...</td>\n",
       "      <td>[kurosawa, going, easy, visual, shock, deeper,...</td>\n",
       "      <td>[kurosawa, going, easy, visual, shock, deeper,...</td>\n",
       "      <td>kurosawa going easy visual shock deeper metaph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>of any horror filmmaker in the world , kiyoshi...</td>\n",
       "      <td>1</td>\n",
       "      <td>of any horror filmmaker in the world  kiyoshi ...</td>\n",
       "      <td>of any horror filmmaker in the world  kiyoshi ...</td>\n",
       "      <td>of any horror filmmaker in the world kiyoshi k...</td>\n",
       "      <td>[of, any, horror, filmmaker, in, the, world, k...</td>\n",
       "      <td>[horror, filmmaker, world, kiyoshi, kurosawa, ...</td>\n",
       "      <td>[horror, filmmaker, world, kiyoshi, kurosawa, ...</td>\n",
       "      <td>horror filmmaker world kiyoshi kurosawa one wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>i rate this metaphysical look at isolation a 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>i rate this metaphysical look at isolation a  ...</td>\n",
       "      <td>i rate this metaphysical look at isolation a  ...</td>\n",
       "      <td>i rate this metaphysical look at isolation a o...</td>\n",
       "      <td>[i, rate, this, metaphysical, look, at, isolat...</td>\n",
       "      <td>[rate, metaphysical, look, isolation, scale, s...</td>\n",
       "      <td>[rate, metaphysical, look, isolation, scale, s...</td>\n",
       "      <td>rate metaphysical look isolation scale scale r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentiment  \\\n",
       "0                                            bad . bad .          0   \n",
       "1                                                  bad .          0   \n",
       "2      that one word seems to pretty much sums up bey...          0   \n",
       "3      if that summary isn't enough for you , how abo...          0   \n",
       "4                          still haven't got the point ?          0   \n",
       "...                                                  ...        ...   \n",
       "64715  people are shot with guns but there is little ...          1   \n",
       "64716  seeing black silhouettes on computer screens i...          1   \n",
       "64717  kurosawa is not going for and easy visual shoc...          1   \n",
       "64718  of any horror filmmaker in the world , kiyoshi...          1   \n",
       "64719  i rate this metaphysical look at isolation a 7...          1   \n",
       "\n",
       "                                              text_clean  \\\n",
       "0                                               bad  bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you  how about...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world  kiyoshi ...   \n",
       "64719  i rate this metaphysical look at isolation a  ...   \n",
       "\n",
       "                                             casefolding  \\\n",
       "0                                               bad  bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you  how about...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world  kiyoshi ...   \n",
       "64719  i rate this metaphysical look at isolation a  ...   \n",
       "\n",
       "                                          text_deslanged  \\\n",
       "0                                                bad bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you how about ...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world kiyoshi k...   \n",
       "64719  i rate this metaphysical look at isolation a o...   \n",
       "\n",
       "                                       text_preprocessed  \\\n",
       "0                                             [bad, bad]   \n",
       "1                                                  [bad]   \n",
       "2      [that, one, word, seems, to, pretty, much, sum...   \n",
       "3      [if, that, summary, is, nt, enough, for, you, ...   \n",
       "4                     [still, have, nt, got, the, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, are, shot, with, guns, but, there, is...   \n",
       "64716  [seeing, black, silhouettes, on, computer, scr...   \n",
       "64717  [kurosawa, is, not, going, for, and, easy, vis...   \n",
       "64718  [of, any, horror, filmmaker, in, the, world, k...   \n",
       "64719  [i, rate, this, metaphysical, look, at, isolat...   \n",
       "\n",
       "                                           text_filtered  \\\n",
       "0                                   [bad, bad, bad, bad]   \n",
       "1                                             [bad, bad]   \n",
       "2      [one, word, seems, pretty, much, sums, beyond,...   \n",
       "3      [summary, nt, enough, ta, ta, ta, summary, nt,...   \n",
       "4         [still, nt, got, point, still, nt, got, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, shot, guns, little, blood, evidence, ...   \n",
       "64716  [seeing, black, silhouettes, computer, screens...   \n",
       "64717  [kurosawa, going, easy, visual, shock, deeper,...   \n",
       "64718  [horror, filmmaker, world, kiyoshi, kurosawa, ...   \n",
       "64719  [rate, metaphysical, look, isolation, scale, s...   \n",
       "\n",
       "                                            text_stemmed  \\\n",
       "0                                   [bad, bad, bad, bad]   \n",
       "1                                             [bad, bad]   \n",
       "2      [one, word, seems, pretty, much, sum, beyond, ...   \n",
       "3      [summary, nt, enough, ta, ta, ta, summary, nt,...   \n",
       "4         [still, nt, got, point, still, nt, got, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, shot, gun, little, blood, evidence, p...   \n",
       "64716  [seeing, black, silhouette, computer, screen, ...   \n",
       "64717  [kurosawa, going, easy, visual, shock, deeper,...   \n",
       "64718  [horror, filmmaker, world, kiyoshi, kurosawa, ...   \n",
       "64719  [rate, metaphysical, look, isolation, scale, s...   \n",
       "\n",
       "                                         text_classifier  \n",
       "0                                        bad bad bad bad  \n",
       "1                                                bad bad  \n",
       "2      one word seems pretty much sums beyond valley ...  \n",
       "3      summary nt enough ta ta ta summary nt enough t...  \n",
       "4                  still nt got point still nt got point  \n",
       "...                                                  ...  \n",
       "64715  people shot guns little blood evidence people ...  \n",
       "64716  seeing black silhouettes computer screens imme...  \n",
       "64717  kurosawa going easy visual shock deeper metaph...  \n",
       "64718  horror filmmaker world kiyoshi kurosawa one wa...  \n",
       "64719  rate metaphysical look isolation scale scale r...  \n",
       "\n",
       "[64720 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_ngram_vectorizer = TfidfVectorizer()\n",
    "X = df['text_classifier']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_bi = tf_idf_ngram_vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bi, y, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can experiment with different kernels (e.g., 'rbf', 'poly')\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.6784243  0.6791967  0.65825393 0.67937162 0.67911409 0.67164563\n",
      " 0.68658254 0.67808396 0.68503734 0.68297708]\n",
      "Mean cross-validation score: 0.6778687195207502\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(svm_model, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6812036464771323\n",
      "Confusion Matrix:\n",
      " [[8521 4151]\n",
      " [4102 9114]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67     12672\n",
      "           1       0.69      0.69      0.69     13216\n",
      "\n",
      "    accuracy                           0.68     25888\n",
      "   macro avg       0.68      0.68      0.68     25888\n",
      "weighted avg       0.68      0.68      0.68     25888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "hidden_size = 2  # Replace with your desired hidden layer size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Split the data into train and test sets\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m data_train, data_test, labels_train, labels_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Convert back to tensors after splitting\u001b[39;00m\n\u001b[1;32m     21\u001b[0m data_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Convert csr_matrix to a dense format and explicitly specify the dtype\n",
    "data = torch.tensor(X_bi.toarray(), dtype=torch.float32).unsqueeze(-1)  # Convert csr_matrix to dense tensor\n",
    "labels = torch.tensor(y.values, dtype=torch.int64)  # Convert labels to tensor with explicit dtype\n",
    "\n",
    "# Move the data to the GPU\n",
    "data = data.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Define and move the model to the GPU\n",
    "sentimentlstm = LSTM(1, hidden_size, len(torch.unique(labels)))\n",
    "sentimentlstm = sentimentlstm.to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(sentimentlstm.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets (use PyTorch indexing)\n",
    "train_size = int(0.8 * data.size(0))  # 80% for training\n",
    "indices = torch.randperm(data.size(0))  # Random permutation of indices\n",
    "\n",
    "data_train = data[indices[:train_size]]  # Training data\n",
    "labels_train = labels[indices[:train_size]]  # Training labels\n",
    "data_test = data[indices[train_size:]]  # Testing data\n",
    "labels_test = labels[indices[train_size:]]  # Testing labels\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "val_size = int(0.25 * train_size)  # 25% of training data for validation\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = train_indices[:val_size]  # Validation indices\n",
    "\n",
    "data_val = data[train_indices[val_size:]]  # Validation data\n",
    "labels_val = labels[train_indices[val_size:]]  # Validation labels\n",
    "data_train = data[train_indices[val_size:]]  # Update training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 766900324536 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 19\u001b[0m     outputs_val \u001b[38;5;241m=\u001b[39m \u001b[43msentimentlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m criterion(outputs_val, labels_val)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 11\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     10\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 11\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 766900324536 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "# Training loop with smaller batches\n",
    "batch_size = 32  # or any number that fits your memory constraints\n",
    "num_batches = len(data_train) // batch_size\n",
    "\n",
    "for epoch in range(3000):  # Number of epochs\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        optimizer.zero_grad()   # Clear gradients for the next mini-batch\n",
    "        outputs_train = sentimentlstm(data_train[start:end])  # Forward pass\n",
    "        loss_train = criterion(outputs_train, labels_train[start:end])  # Compute the loss\n",
    "        loss_train.backward()         # Backward pass\n",
    "        optimizer.step()        # Update the weights\n",
    "        # Validation phase\n",
    "        with torch.no_grad():\n",
    "            outputs_val = sentimentlstm(data_val)\n",
    "            loss_val = criterion(outputs_val, labels_val)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs_val.data, 1)\n",
    "            total = labels_val.size(0)\n",
    "            correct = (predicted == labels_val).sum().item()\n",
    "            accuracy = correct / total\n",
    "        # Print training and validation loss for each epoch\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {loss_train.item()}, Validation Loss: {loss_val.item()}')\n",
    "\n",
    "# Get the model's predictions on the test data\n",
    "sentimentlstm.eval()  # Set the sentimentlstm to evaluation mode\n",
    "with torch.no_grad():  # Temporarily turn off gradient descent\n",
    "    outputs_test = sentimentlstm(data_test)\n",
    "    _, predicted_labels = torch.max(outputs_test, 1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(labels_test.cpu().numpy(), predicted_labels.cpu().numpy())\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(labels_test.cpu().numpy(), predicted_labels.cpu().numpy())\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
