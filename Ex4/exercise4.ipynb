{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.0-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/Exercise/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/Exercise/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/Exercise/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/Exercise/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/Exercise/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.5.0-cp310-none-macosx_11_0_arm64.whl (64.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/ruzmanraja/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: make me the slangremover function for english language with working slang_dict from github\n",
    "\n",
    "slang_dict = {\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"lmfao\": \"laughing my f***ing ass off\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"diy\": \"do it yourself\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"nvm\": \"nevermind\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"nvm\": \"nevermind\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ttyl\": \"talk to you later\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "\n",
    "    text = text.replace('\\n', ' ') # replace new line into space\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
    "    text = text.strip(' ') # remove characters space from both left and right text\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\") \n",
    "\n",
    "def tokenizingText(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]  \n",
    "    return tokens\n",
    "\n",
    "def deSlangText(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.lower() in slang_dict:\n",
    "            new_text.append(slang_dict[word.lower()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def filteringText(text):  # Remove stopwords in a text\n",
    "    listStopwords = set(stopwords.words('english'))\n",
    "    filtered = [w for w in text if not w.lower() in listStopwords]\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    "\n",
    "# Lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_words\n",
    "\n",
    "def stemmingText(text):  # Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
    "    stemmer = PorterStemmer()\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "def toSentence(list_words): # Convert list of words into sentence\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = tokenizingText(example_sent)\n",
    "# converts the words in word_tokens to lower case and then checks whether \n",
    "#they are present in stop_words or not\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "#with no lower case conversion\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "\tif w not in stop_words:\n",
    "\t\tfiltered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad . bad .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if that summary isn't enough for you , how abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>still haven't got the point ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>of any horror filmmaker in the world , kiyoshi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>i rate this metaphysical look at isolation a 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentiment\n",
       "0                                            bad . bad .          0\n",
       "1                                                  bad .          0\n",
       "2      that one word seems to pretty much sums up bey...          0\n",
       "3      if that summary isn't enough for you , how abo...          0\n",
       "4                          still haven't got the point ?          0\n",
       "...                                                  ...        ...\n",
       "64715  people are shot with guns but there is little ...          1\n",
       "64716  seeing black silhouettes on computer screens i...          1\n",
       "64717  kurosawa is not going for and easy visual shoc...          1\n",
       "64718  of any horror filmmaker in the world , kiyoshi...          1\n",
       "64719  i rate this metaphysical look at isolation a 7...          1\n",
       "\n",
       "[64720 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('output_sentences.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['sentence'].astype(str).apply(cleaningText)\n",
    "df['casefolding'] = df['text_clean'].apply(casefoldingText)\n",
    "df['text_deslanged'] = df['casefolding'].apply(deSlangText)\n",
    "df['text_preprocessed'] = df['text_deslanged'].apply(tokenizingText)\n",
    "df['text_filtered'] = df['text_preprocessed'].apply(filteringText)\n",
    "df['text_stemmed'] = df['text_filtered'].apply(lemmatize_text)\n",
    "df['text_classifier'] = df['text_filtered'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>casefolding</th>\n",
       "      <th>text_deslanged</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>text_filtered</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad . bad .</td>\n",
       "      <td>0</td>\n",
       "      <td>bad  bad</td>\n",
       "      <td>bad  bad</td>\n",
       "      <td>bad bad</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>[bad, bad, bad, bad]</td>\n",
       "      <td>[bad, bad, bad, bad]</td>\n",
       "      <td>bad bad bad bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad .</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>[bad]</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>[bad, bad]</td>\n",
       "      <td>bad bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>0</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>that one word seems to pretty much sums up bey...</td>\n",
       "      <td>[that, one, word, seems, to, pretty, much, sum...</td>\n",
       "      <td>[one, word, seems, pretty, much, sums, beyond,...</td>\n",
       "      <td>[one, word, seems, pretty, much, sum, beyond, ...</td>\n",
       "      <td>one word seems pretty much sums beyond valley ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if that summary isn't enough for you , how abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>if that summary isnt enough for you  how about...</td>\n",
       "      <td>if that summary isnt enough for you  how about...</td>\n",
       "      <td>if that summary isnt enough for you how about ...</td>\n",
       "      <td>[if, that, summary, is, nt, enough, for, you, ...</td>\n",
       "      <td>[summary, nt, enough, ta, ta, ta, summary, nt,...</td>\n",
       "      <td>[summary, nt, enough, ta, ta, ta, summary, nt,...</td>\n",
       "      <td>summary nt enough ta ta ta summary nt enough t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>still haven't got the point ?</td>\n",
       "      <td>0</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>still havent got the point</td>\n",
       "      <td>[still, have, nt, got, the, point]</td>\n",
       "      <td>[still, nt, got, point, still, nt, got, point]</td>\n",
       "      <td>[still, nt, got, point, still, nt, got, point]</td>\n",
       "      <td>still nt got point still nt got point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>1</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>people are shot with guns but there is little ...</td>\n",
       "      <td>[people, are, shot, with, guns, but, there, is...</td>\n",
       "      <td>[people, shot, guns, little, blood, evidence, ...</td>\n",
       "      <td>[people, shot, gun, little, blood, evidence, p...</td>\n",
       "      <td>people shot guns little blood evidence people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>1</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>seeing black silhouettes on computer screens i...</td>\n",
       "      <td>[seeing, black, silhouettes, on, computer, scr...</td>\n",
       "      <td>[seeing, black, silhouettes, computer, screens...</td>\n",
       "      <td>[seeing, black, silhouette, computer, screen, ...</td>\n",
       "      <td>seeing black silhouettes computer screens imme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>kurosawa is not going for and easy visual shoc...</td>\n",
       "      <td>[kurosawa, is, not, going, for, and, easy, vis...</td>\n",
       "      <td>[kurosawa, going, easy, visual, shock, deeper,...</td>\n",
       "      <td>[kurosawa, going, easy, visual, shock, deeper,...</td>\n",
       "      <td>kurosawa going easy visual shock deeper metaph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>of any horror filmmaker in the world , kiyoshi...</td>\n",
       "      <td>1</td>\n",
       "      <td>of any horror filmmaker in the world  kiyoshi ...</td>\n",
       "      <td>of any horror filmmaker in the world  kiyoshi ...</td>\n",
       "      <td>of any horror filmmaker in the world kiyoshi k...</td>\n",
       "      <td>[of, any, horror, filmmaker, in, the, world, k...</td>\n",
       "      <td>[horror, filmmaker, world, kiyoshi, kurosawa, ...</td>\n",
       "      <td>[horror, filmmaker, world, kiyoshi, kurosawa, ...</td>\n",
       "      <td>horror filmmaker world kiyoshi kurosawa one wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>i rate this metaphysical look at isolation a 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>i rate this metaphysical look at isolation a  ...</td>\n",
       "      <td>i rate this metaphysical look at isolation a  ...</td>\n",
       "      <td>i rate this metaphysical look at isolation a o...</td>\n",
       "      <td>[i, rate, this, metaphysical, look, at, isolat...</td>\n",
       "      <td>[rate, metaphysical, look, isolation, scale, s...</td>\n",
       "      <td>[rate, metaphysical, look, isolation, scale, s...</td>\n",
       "      <td>rate metaphysical look isolation scale scale r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentiment  \\\n",
       "0                                            bad . bad .          0   \n",
       "1                                                  bad .          0   \n",
       "2      that one word seems to pretty much sums up bey...          0   \n",
       "3      if that summary isn't enough for you , how abo...          0   \n",
       "4                          still haven't got the point ?          0   \n",
       "...                                                  ...        ...   \n",
       "64715  people are shot with guns but there is little ...          1   \n",
       "64716  seeing black silhouettes on computer screens i...          1   \n",
       "64717  kurosawa is not going for and easy visual shoc...          1   \n",
       "64718  of any horror filmmaker in the world , kiyoshi...          1   \n",
       "64719  i rate this metaphysical look at isolation a 7...          1   \n",
       "\n",
       "                                              text_clean  \\\n",
       "0                                               bad  bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you  how about...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world  kiyoshi ...   \n",
       "64719  i rate this metaphysical look at isolation a  ...   \n",
       "\n",
       "                                             casefolding  \\\n",
       "0                                               bad  bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you  how about...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world  kiyoshi ...   \n",
       "64719  i rate this metaphysical look at isolation a  ...   \n",
       "\n",
       "                                          text_deslanged  \\\n",
       "0                                                bad bad   \n",
       "1                                                    bad   \n",
       "2      that one word seems to pretty much sums up bey...   \n",
       "3      if that summary isnt enough for you how about ...   \n",
       "4                             still havent got the point   \n",
       "...                                                  ...   \n",
       "64715  people are shot with guns but there is little ...   \n",
       "64716  seeing black silhouettes on computer screens i...   \n",
       "64717  kurosawa is not going for and easy visual shoc...   \n",
       "64718  of any horror filmmaker in the world kiyoshi k...   \n",
       "64719  i rate this metaphysical look at isolation a o...   \n",
       "\n",
       "                                       text_preprocessed  \\\n",
       "0                                             [bad, bad]   \n",
       "1                                                  [bad]   \n",
       "2      [that, one, word, seems, to, pretty, much, sum...   \n",
       "3      [if, that, summary, is, nt, enough, for, you, ...   \n",
       "4                     [still, have, nt, got, the, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, are, shot, with, guns, but, there, is...   \n",
       "64716  [seeing, black, silhouettes, on, computer, scr...   \n",
       "64717  [kurosawa, is, not, going, for, and, easy, vis...   \n",
       "64718  [of, any, horror, filmmaker, in, the, world, k...   \n",
       "64719  [i, rate, this, metaphysical, look, at, isolat...   \n",
       "\n",
       "                                           text_filtered  \\\n",
       "0                                   [bad, bad, bad, bad]   \n",
       "1                                             [bad, bad]   \n",
       "2      [one, word, seems, pretty, much, sums, beyond,...   \n",
       "3      [summary, nt, enough, ta, ta, ta, summary, nt,...   \n",
       "4         [still, nt, got, point, still, nt, got, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, shot, guns, little, blood, evidence, ...   \n",
       "64716  [seeing, black, silhouettes, computer, screens...   \n",
       "64717  [kurosawa, going, easy, visual, shock, deeper,...   \n",
       "64718  [horror, filmmaker, world, kiyoshi, kurosawa, ...   \n",
       "64719  [rate, metaphysical, look, isolation, scale, s...   \n",
       "\n",
       "                                            text_stemmed  \\\n",
       "0                                   [bad, bad, bad, bad]   \n",
       "1                                             [bad, bad]   \n",
       "2      [one, word, seems, pretty, much, sum, beyond, ...   \n",
       "3      [summary, nt, enough, ta, ta, ta, summary, nt,...   \n",
       "4         [still, nt, got, point, still, nt, got, point]   \n",
       "...                                                  ...   \n",
       "64715  [people, shot, gun, little, blood, evidence, p...   \n",
       "64716  [seeing, black, silhouette, computer, screen, ...   \n",
       "64717  [kurosawa, going, easy, visual, shock, deeper,...   \n",
       "64718  [horror, filmmaker, world, kiyoshi, kurosawa, ...   \n",
       "64719  [rate, metaphysical, look, isolation, scale, s...   \n",
       "\n",
       "                                         text_classifier  \n",
       "0                                        bad bad bad bad  \n",
       "1                                                bad bad  \n",
       "2      one word seems pretty much sums beyond valley ...  \n",
       "3      summary nt enough ta ta ta summary nt enough t...  \n",
       "4                  still nt got point still nt got point  \n",
       "...                                                  ...  \n",
       "64715  people shot guns little blood evidence people ...  \n",
       "64716  seeing black silhouettes computer screens imme...  \n",
       "64717  kurosawa going easy visual shock deeper metaph...  \n",
       "64718  horror filmmaker world kiyoshi kurosawa one wa...  \n",
       "64719  rate metaphysical look isolation scale scale r...  \n",
       "\n",
       "[64720 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_ngram_vectorizer = TfidfVectorizer()\n",
    "X = df['text_classifier']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_bi = tf_idf_ngram_vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bi, y, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can experiment with different kernels (e.g., 'rbf', 'poly')\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.6784243  0.6791967  0.65825393 0.67937162 0.67911409 0.67164563\n",
      " 0.68658254 0.67808396 0.68503734 0.68297708]\n",
      "Mean cross-validation score: 0.6778687195207502\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(svm_model, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6812036464771323\n",
      "Confusion Matrix:\n",
      " [[8521 4151]\n",
      " [4102 9114]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67     12672\n",
      "           1       0.69      0.69      0.69     13216\n",
      "\n",
      "    accuracy                           0.68     25888\n",
      "   macro avg       0.68      0.68      0.68     25888\n",
      "weighted avg       0.68      0.68      0.68     25888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_bi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert sparse matrix to dense and then to PyTorch tensors\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_bi_dense \u001b[38;5;241m=\u001b[39m \u001b[43mX_bi\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m      3\u001b[0m X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_bi_dense, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      4\u001b[0m y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_bi' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert sparse matrix to dense and then to PyTorch tensors\n",
    "X_bi_dense = X_bi.toarray()\n",
    "X_tensor = torch.tensor(X_bi_dense, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.4, random_state=42)\n",
    "\n",
    "# Create DataLoader for training and test sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "input_dim = X_bi_dense.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
